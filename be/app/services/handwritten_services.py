# handwritten_services.py

import os
import cv2
import numpy as np
from app.services.ocr.handwriting_model import VietnameseOCR
import re
def sanitize(obj):
    """Chuy·ªÉn c√°c ki·ªÉu kh√¥ng ph·∫£i native Python sang ki·ªÉu JSON-friendly"""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    if isinstance(obj, np.generic):
        return obj.item()
    if isinstance(obj, dict):
        return {k: sanitize(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [sanitize(v) for v in obj]
    return obj


def merge_nearby_boxes(boxes, horizontal_threshold=30, vertical_threshold=20):
    """
    G·ªôp c√°c bounding box g·∫ßn nhau th√†nh 1 box l·ªõn h∆°n
    
    Tham s·ªë:
    - boxes: danh s√°ch c√°c box [(x, y, w, h), ...]
    - horizontal_threshold: kho·∫£ng c√°ch ngang t·ªëi ƒëa ƒë·ªÉ g·ªôp (pixels)
    - vertical_threshold: kho·∫£ng c√°ch d·ªçc t·ªëi ƒëa ƒë·ªÉ coi l√† c√πng h√†ng (pixels)
    
    Returns:
    - merged_boxes: danh s√°ch c√°c box ƒë√£ g·ªôp [(x, y, w, h), ...]
    """
    if len(boxes) == 0:
        return []
    
    # Chuy·ªÉn sang ƒë·ªãnh d·∫°ng [x1, y1, x2, y2] ƒë·ªÉ d·ªÖ t√≠nh to√°n
    boxes_xyxy = []
    for (x, y, w, h) in boxes:
        boxes_xyxy.append([x, y, x + w, y + h])
    
    boxes_xyxy = np.array(boxes_xyxy)
    
    # S·∫Øp x·∫øp theo y (h√†ng ngang), sau ƒë√≥ theo x (tr√°i -> ph·∫£i)
    indices = np.lexsort((boxes_xyxy[:, 0], boxes_xyxy[:, 1]))
    boxes_sorted = boxes_xyxy[indices]
    
    merged = []
    visited = set()
    
    for i in range(len(boxes_sorted)):
        if i in visited:
            continue
        
        # B·∫Øt ƒë·∫ßu m·ªôt nh√≥m m·ªõi
        group = [i]
        visited.add(i)
        
        current_box = boxes_sorted[i].copy()
        
        # T√¨m c√°c box kh√°c c√πng h√†ng v√† g·∫ßn nhau
        for j in range(i + 1, len(boxes_sorted)):
            if j in visited:
                continue
            
            next_box = boxes_sorted[j]
            
            # Ki·ªÉm tra c√πng h√†ng ngang (overlap v·ªÅ chi·ªÅu d·ªçc)
            y1_center = (current_box[1] + current_box[3]) / 2
            y2_top = next_box[1]
            y2_bottom = next_box[3]
            y2_center = (y2_top + y2_bottom) / 2
            
            # C√πng h√†ng n·∫øu trung t√¢m c·ªßa box n√†y n·∫±m trong v√πng c·ªßa box kia
            vertical_aligned = abs(y1_center - y2_center) <= vertical_threshold
            
            # Ki·ªÉm tra kho·∫£ng c√°ch ngang
            horizontal_gap = next_box[0] - current_box[2]  # kho·∫£ng c√°ch gi·ªØa 2 box
            
            if vertical_aligned and horizontal_gap <= horizontal_threshold:
                # G·ªôp v√†o nh√≥m
                group.append(j)
                visited.add(j)
                
                # M·ªü r·ªông current_box ƒë·ªÉ bao g·ªìm next_box
                current_box[0] = min(current_box[0], next_box[0])
                current_box[1] = min(current_box[1], next_box[1])
                current_box[2] = max(current_box[2], next_box[2])
                current_box[3] = max(current_box[3], next_box[3])
        
        # L∆∞u box ƒë√£ merge
        x1, y1, x2, y2 = current_box
        merged.append((int(x1), int(y1), int(x2 - x1), int(y2 - y1)))
    
    return merged


def visualize_boxes(img, boxes, color=(0, 255, 0), label=""):
    """
    V·∫Ω bounding boxes l√™n ·∫£nh ƒë·ªÉ debug
    """
    img_vis = img.copy()
    for i, (x, y, w, h) in enumerate(boxes):
        cv2.rectangle(img_vis, (x, y), (x + w, y + h), color, 2)
        cv2.putText(img_vis, f"{label}{i}", (x, y - 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    return img_vis


def extract_colored_regions(image_path, output_folder, prefix, 
                           merge_horizontal=True, 
                           horizontal_threshold=30,
                           vertical_threshold=20,
                           save_visualization=True):
    """
    T√°ch ch·ªØ xanh & ƒë·ªè, l·∫•y bounding box v√† l∆∞u c√°c v√πng crop ra folder.
    
    Tham s·ªë m·ªõi:
    - merge_horizontal: True ƒë·ªÉ g·ªôp c√°c box g·∫ßn nhau theo h√†ng ngang
    - horizontal_threshold: kho·∫£ng c√°ch ngang t·ªëi ƒëa ƒë·ªÉ g·ªôp (pixels)
    - vertical_threshold: kho·∫£ng c√°ch d·ªçc t·ªëi ƒëa ƒë·ªÉ coi l√† c√πng h√†ng
    - save_visualization: True ƒë·ªÉ l∆∞u ·∫£nh c√≥ v·∫Ω bounding box
    
    Tr·∫£ v·ªÅ:
        blue_boxes  = [(crop_path, x, y, w, h), ...]
        red_boxes   = [(crop_path, x, y, w, h), ...]
    """
    os.makedirs(output_folder, exist_ok=True)

    img = cv2.imread(image_path)
    if img is None:
        return [], []

    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # Mask ch·ªØ xanh
    lower_blue = np.array([90, 50, 50])
    upper_blue = np.array([135, 255, 255])
    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)

    # Mask ch·ªØ ƒë·ªè (2 kho·∫£ng hue)
    lower_red1 = np.array([0, 70, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 70, 50])
    upper_red2 = np.array([180, 255, 255])
    mask_red = cv2.inRange(hsv, lower_red1, upper_red1) | cv2.inRange(hsv, lower_red2, upper_red2)

    # Morphology l√†m m∆∞·ª£t
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    mask_blue = cv2.morphologyEx(mask_blue, cv2.MORPH_CLOSE, kernel)
    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_CLOSE, kernel)

    # T√¨m contours + l·∫•y bounding box
    blue_boxes_raw, red_boxes_raw = [], []

    # Thu th·∫≠p t·∫•t c·∫£ boxes tr∆∞·ªõc khi merge
    for mask, box_list in [(mask_blue, blue_boxes_raw), (mask_red, red_boxes_raw)]:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            if w < 10 or h < 10:  # l·ªçc noise nh·ªè
                continue
            box_list.append((x, y, w, h))
    
    # Merge boxes n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if merge_horizontal:
        print(f"  üì¶ Tr∆∞·ªõc merge: {len(blue_boxes_raw)} blue boxes, {len(red_boxes_raw)} red boxes")
        blue_boxes_merged = merge_nearby_boxes(blue_boxes_raw, horizontal_threshold, vertical_threshold)
        red_boxes_merged = merge_nearby_boxes(red_boxes_raw, horizontal_threshold, vertical_threshold)
        print(f"  ‚úÖ Sau merge: {len(blue_boxes_merged)} blue boxes, {len(red_boxes_merged)} red boxes")
    else:
        blue_boxes_merged = blue_boxes_raw
        red_boxes_merged = red_boxes_raw
    
    # L∆∞u visualization n·∫øu c·∫ßn
    if save_visualization:
        vis_img = img.copy()
        
        # V·∫Ω boxes tr∆∞·ªõc merge (m√†u nh·∫°t)
        for (x, y, w, h) in blue_boxes_raw:
            cv2.rectangle(vis_img, (x, y), (x + w, y + h), (200, 200, 255), 1)
        for (x, y, w, h) in red_boxes_raw:
            cv2.rectangle(vis_img, (x, y), (x + w, y + h), (200, 200, 200), 1)
        
        # V·∫Ω boxes sau merge (m√†u ƒë·∫≠m)
        for i, (x, y, w, h) in enumerate(blue_boxes_merged):
            cv2.rectangle(vis_img, (x, y), (x + w, y + h), (255, 0, 0), 2)
            cv2.putText(vis_img, f"B{i}", (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        for i, (x, y, w, h) in enumerate(red_boxes_merged):
            cv2.rectangle(vis_img, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.putText(vis_img, f"R{i}", (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        vis_path = os.path.join(output_folder, f"{prefix}_visualization.jpg")
        cv2.imwrite(vis_path, vis_img)
        print(f"  üíæ ƒê√£ l∆∞u visualization: {vis_path}")
    
    # Crop v√† l∆∞u c√°c v√πng ƒë√£ merge
    blue_boxes_final, red_boxes_final = [], []
    
    for i, (x, y, w, h) in enumerate(blue_boxes_merged):
        crop = img[y:y+h, x:x+w]
        crop_name = f"{prefix}_blue_{i}.png"
        crop_path = os.path.join(output_folder, crop_name)
        cv2.imwrite(crop_path, crop)
        blue_boxes_final.append((crop_path, int(x), int(y), int(w), int(h)))
    
    for i, (x, y, w, h) in enumerate(red_boxes_merged):
        crop = img[y:y+h, x:x+w]
        crop_name = f"{prefix}_red_{i}.png"
        crop_path = os.path.join(output_folder, crop_name)
        cv2.imwrite(crop_path, crop)
        red_boxes_final.append((crop_path, int(x), int(y), int(w), int(h)))

    return blue_boxes_final, red_boxes_final

def _clean_spacing(text: str) -> str:
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'\s+([,.;:!?])', r'\1', text)  # remove space before punctuation
    text = re.sub(r'([(\["])\s+', r'\1', text)
    return text

def combine_region_texts(regions, prefer='handwritten', join_with=' ' , line_threshold=None):
    """
    G·ªôp c√°c ƒëo·∫°n text t·ª´ danh s√°ch regions th√†nh 1 ƒëo·∫°n vƒÉn.
    - regions: list of {'bbox':[x,y,w,h], 'handwritten':[...], 'printed':[...], ...}
    - prefer: 'handwritten' | 'printed' | 'mixed' (∆∞u ti√™n l·∫•y text)
    - join_with: k√Ω t·ª± n·ªëi gi·ªØa c√°c segment (m·∫∑c ƒë·ªãnh ' ')
    - line_threshold: n·∫øu truy·ªÅn (pixels) -> n·∫øu kho·∫£ng c√°ch d·ªçc gi·ªØa 2 region > threshold s·∫Ω ch√®n newline
                       (m·∫∑c ƒë·ªãnh None: kh√¥ng ch√®n newline, tr·∫£ v·ªÅ 1 ƒëo·∫°n)
    Tr·∫£ v·ªÅ: chu·ªói vƒÉn b·∫£n ƒë√£ g·ªôp.
    """
    segs = []
    for r in regions:
        bbox = r.get('bbox') or [0,0,0,0]
        x, y, w, h = bbox if len(bbox) == 4 else (bbox[0], bbox[1], 0, 0)
        y_center = y + h / 2
        # Ch·ªçn text theo prefer
        if prefer == 'handwritten':
            texts = r.get('handwritten', []) or []
        elif prefer == 'printed':
            texts = r.get('printed', []) or []
        else:  # mixed
            texts = (r.get('handwritten') or []) + (r.get('printed') or [])
        # flatten v√† n·ªëi c√°c ph·∫ßn trong region
        seg_text = ' '.join([t for t in texts if t])
        seg_text = _clean_spacing(seg_text)
        if seg_text:
            segs.append((y_center, x, seg_text))

    # S·∫Øp x·∫øp top->bottom, left->right
    segs.sort(key=lambda item: (item[0], item[1]))

    if not segs:
        return ""

    parts = []
    prev_y = None
    for y_center, x, text in segs:
        if line_threshold is not None and prev_y is not None:
            if abs(y_center - prev_y) > line_threshold:
                parts.append('\n')  # ng·∫Øt ƒëo·∫°n n·∫øu kho·∫£ng c√°ch l·ªõn
        parts.append(text)
        prev_y = y_center

    paragraph = join_with.join([p for p in parts if p is not None])
    paragraph = _clean_spacing(paragraph)
    return paragraph

GLOBAL_OCR_ENGINE = None

def get_ocr_engine(use_ml=False):
    global GLOBAL_OCR_ENGINE
    if GLOBAL_OCR_ENGINE is None:
        print("‚è≥ ƒêang t·∫£i model OCR l·∫ßn ƒë·∫ßu ti√™n...")
        GLOBAL_OCR_ENGINE = VietnameseOCR(use_ml_classifier=use_ml)
        print("‚úÖ ƒê√£ t·∫£i xong model OCR!")
    return GLOBAL_OCR_ENGINE

def process_handwritten_folder(folder_path: str, 
                               merge_horizontal=True,
                               horizontal_threshold=30,
                               vertical_threshold=20,
                               use_ml_classifier=False):
    """
    X·ª≠ l√Ω to√†n b·ªô ·∫£nh trong 1 folder (qX ho·∫∑c aX)
    """
    results = []
    bbox_output = os.path.join(folder_path, "_bbox")
    os.makedirs(bbox_output, exist_ok=True)
    
    # 1. L·∫•y Engine (Singleton)
    ocr_engine = get_ocr_engine(use_ml=use_ml_classifier)

    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if filename == "_bbox" or not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            continue

        print("\n" + "="*70)
        print(f"üìÑ Processing file: {filename}")

        # 2. T√°ch m√†u & Crop
        blue_boxes, red_boxes = extract_colored_regions(
            file_path, 
            bbox_output, 
            prefix=filename.split('.')[0],
            merge_horizontal=merge_horizontal,
            horizontal_threshold=horizontal_threshold,
            vertical_threshold=vertical_threshold,
            save_visualization=True
        )

        # 3. Chu·∫©n b·ªã danh s√°ch task (S·ª¨A L·∫†I ƒêO·∫†N N√ÄY ƒê·ªÇ TR√ÅNH L·ªñI TUPLE)
        all_tasks = []
        
        # blue_boxes l√† list c√°c tuple: (crop_path, x, y, w, h)
        for item in blue_boxes:
            all_tasks.append({
                "crop_path": item[0],       # L·∫•y path t·ª´ tuple
                "bbox": item[1:],           # L·∫•y (x, y, w, h)
                "color": "blue"             # G√°n m√†u th·ªß c√¥ng
            })
            
        for item in red_boxes:
            all_tasks.append({
                "crop_path": item[0],
                "bbox": item[1:],
                "color": "red"
            })

        # Danh s√°ch ch·ª©a k·∫øt qu·∫£ sau khi AI ƒë·ªçc
        results_hw = []       # Ch·ª©a k·∫øt qu·∫£ ƒë∆∞·ª£c model Handwritten ƒë·ªçc
        results_printed = []  # Ch·ª©a k·∫øt qu·∫£ ƒë∆∞·ª£c model Printed ƒë·ªçc

        print(f"‚ö° B·∫Øt ƒë·∫ßu x·ª≠ l√Ω th√¥ng minh {len(all_tasks)} v√πng ·∫£nh...")

        for task in all_tasks:
            # Truy c·∫≠p b·∫±ng key dictionary thay v√¨ index
            crop_path = task["crop_path"]
            
            # 4. Routing th√¥ng minh: Ph√¢n lo·∫°i -> Ch·ªçn Model -> ƒê·ªçc
            text_result, detected_type = ocr_engine.process_crop(crop_path)
            
            # T·∫°o object k·∫øt qu·∫£ chu·∫©n
            result_item = {
                "text": text_result,
                "bbox": task["bbox"],         # [x, y, w, h]
                "source_color": task["color"],# blue/red
                "type": detected_type         # handwritten/printed
            }

            # Ph√¢n lo·∫°i v√†o danh s√°ch
            if detected_type == 'handwritten':
                results_hw.append(result_item)
            else:
                results_printed.append(result_item)

        # 5. G·ªôp text v√† l∆∞u file
        base_name = os.path.splitext(filename)[0]
        
        # G·ªôp danh s√°ch k·∫øt qu·∫£
        all_regions = results_hw + results_printed
        
        # Map l·∫°i d·ªØ li·ªáu ƒë·ªÉ h√†m combine_region_texts hi·ªÉu ƒë∆∞·ª£c
        mapped_regions = []
        for r in all_regions:
            item = {'bbox': r['bbox']}
            # combine_region_texts c·∫ßn list text trong key 'handwritten' ho·∫∑c 'printed'
            if r['type'] == 'handwritten':
                item['handwritten'] = [r['text']]
            else:
                item['printed'] = [r['text']]
            mapped_regions.append(item)

        combined_handwritten = combine_region_texts(mapped_regions, prefer='handwritten', join_with=' ', line_threshold=vertical_threshold)
        combined_printed = combine_region_texts(mapped_regions, prefer='printed', join_with=' ', line_threshold=vertical_threshold)

        # L∆∞u file .txt
        hw_file_path = os.path.join(folder_path, f"{base_name}_chu_viet_tay.txt")
        printed_file_path = os.path.join(folder_path, f"{base_name}_chu_in.txt")
        try:
            with open(hw_file_path, "w", encoding="utf-8") as f:
                f.write(combined_handwritten or "")
            with open(printed_file_path, "w", encoding="utf-8") as f:
                f.write(combined_printed or "")
            print(f"  üíæ Saved combined handwritten -> {hw_file_path}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error saving combined text files: {e}")

        # 6. Tr·∫£ v·ªÅ k·∫øt qu·∫£ API
        results.append({
            "file": filename,
            "result": combined_handwritten + " " + combined_printed,
        })
        
        print(f"\n‚úÖ Completed: {filename}")
        print(f"  - Handwritten regions detected: {len(results_hw)}")
        print(f"  - Printed regions detected: {len(results_printed)}")

    return sanitize(results)


def process_handwritten_batch(q_folder: str, a_folder: str,
                              merge_horizontal=True,
                              horizontal_threshold=30,
                              vertical_threshold=20,
                              use_ml_classifier=False):
    """
    X·ª≠ l√Ω c·∫£ batch qX + aX
    
    Tham s·ªë:
    - q_folder: th∆∞ m·ª•c c√¢u h·ªèi (qX)
    - a_folder: th∆∞ m·ª•c c√¢u tr·∫£ l·ªùi (aX)
    - merge_horizontal: True ƒë·ªÉ g·ªôp box theo h√†ng ngang
    - horizontal_threshold: kho·∫£ng c√°ch ngang t·ªëi ƒëa ƒë·ªÉ g·ªôp (pixels)
    - vertical_threshold: kho·∫£ng c√°ch d·ªçc t·ªëi ƒëa ƒë·ªÉ coi l√† c√πng h√†ng (pixels)
    - use_ml_classifier: True ƒë·ªÉ d√πng ML classifier, False d√πng rule-based
    """
    full_q_path = os.path.join("uploads/handwritten", q_folder)
    full_a_path = os.path.join("uploads/handwritten", a_folder)
    
    print("\n" + "="*70)
    print("üöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù BATCH")
    print("="*70)
    print(f"üìÅ Question folder: {q_folder}")
    print(f"üìÅ Answer folder: {a_folder}")
    print(f"‚öôÔ∏è  Merge horizontal: {merge_horizontal}")
    print(f"‚öôÔ∏è  Horizontal threshold: {horizontal_threshold}px")
    print(f"‚öôÔ∏è  Vertical threshold: {vertical_threshold}px")
    print(f"ü§ñ ML Classifier: {'Enabled' if use_ml_classifier else 'Rule-based'}")
    print("="*70)

    return {
        "question_results": process_handwritten_folder(
            full_q_path,
            merge_horizontal=merge_horizontal,
            horizontal_threshold=horizontal_threshold,
            vertical_threshold=vertical_threshold,
            use_ml_classifier=use_ml_classifier
        ),
        "answer_results": process_handwritten_folder(
            full_a_path,
            merge_horizontal=merge_horizontal,
            horizontal_threshold=horizontal_threshold,
            vertical_threshold=vertical_threshold,
            use_ml_classifier=use_ml_classifier
        )
    }